{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache directory: /Users/casey/Documents/GitHub/AI_impact_employment/cache\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create cache directory if it doesn't exist\n",
    "cache_dir = \"cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "print(f\"Using cache directory: {os.path.abspath(cache_dir)}\")\n",
    "\n",
    "def get_cache_path(filename):\n",
    "    \"\"\"Get full path for a cache file\"\"\"\n",
    "    return os.path.join(cache_dir, filename)\n",
    "\n",
    "def save_to_cache(obj, filename):\n",
    "    \"\"\"Save object to cache\"\"\"\n",
    "    with open(get_cache_path(filename), 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Saved {filename} to cache\")\n",
    "\n",
    "def load_from_cache(filename):\n",
    "    \"\"\"Load object from cache if it exists\"\"\"\n",
    "    cache_path = get_cache_path(filename)\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Dictionary Creation Functions\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def create_sentiment_dictionaries():\n",
    "    \"\"\"Create dictionaries for domain-specific sentiment analysis\"\"\"\n",
    "    print(\"Creating sentiment dictionaries...\")\n",
    "    \n",
    "    # Positive terms related to AI in workplace context\n",
    "    positive_terms = {\n",
    "        # Opportunity and Growth\n",
    "        'opportunity': 1.0, 'enhance': 0.8, 'improve': 0.8, 'augment': 0.7,\n",
    "        'growth': 0.7, 'advancement': 0.8, 'upskill': 0.9, 'progress': 0.7,\n",
    "        'potential': 0.5, 'revolutionize': 0.8, 'transform': 0.7,\n",
    "\n",
    "        # Productivity and Efficiency\n",
    "        'efficiency': 0.8, 'productivity': 0.8, 'streamline': 0.7,\n",
    "        'optimize': 0.7, 'accelerate': 0.6, 'automate': 0.6,\n",
    "\n",
    "        # Collaboration and Assistance\n",
    "        'assist': 0.6, 'empower': 0.9, 'collaborate': 0.7, 'partnership': 0.6,\n",
    "        'complement': 0.7, 'teamwork': 0.7, 'support': 0.6, 'aid': 0.6,\n",
    "\n",
    "        # Solution and Benefit\n",
    "        'solution': 0.6, 'benefit': 0.8, 'advantage': 0.7, 'value': 0.6,\n",
    "        'solve': 0.7, 'facilitate': 0.6, 'enable': 0.7,\n",
    "\n",
    "        # Innovation and Creation\n",
    "        'innovation': 0.9, 'create': 0.6, 'invent': 0.7, 'develop': 0.6,\n",
    "        'pioneer': 0.8, 'breakthrough': 0.9, 'novel': 0.7\n",
    "    }\n",
    "\n",
    "    # Negative terms related to AI in workplace context\n",
    "    negative_terms = {\n",
    "        # Job Loss and Replacement\n",
    "        'replace': -0.8, 'eliminate': -0.9, 'displace': -0.8, 'substitute': -0.7,\n",
    "        'job loss': -0.9, 'unemployment': -0.9, 'layoff': -0.9, 'redundant': -0.8,\n",
    "        'downsizing': -0.8, 'obsolete': -0.8, 'outdated': -0.7,\n",
    "\n",
    "        # Risk and Threat\n",
    "        'threaten': -0.7, 'risk': -0.6, 'danger': -0.7, 'concern': -0.5,\n",
    "        'worry': -0.6, 'fear': -0.7, 'threat': -0.8, 'harmful': -0.8,\n",
    "\n",
    "        # Problems and Challenges\n",
    "        'controversy': -0.6, 'problem': -0.6, 'challenge': -0.4, 'difficulty': -0.5,\n",
    "        'obstacle': -0.5, 'hurdle': -0.4, 'barrier': -0.5,\n",
    "\n",
    "        # Social Issues\n",
    "        'inequality': -0.7, 'bias': -0.7, 'discrimination': -0.8, 'unfair': -0.7,\n",
    "        'disparity': -0.7, 'divide': -0.6, 'exclusion': -0.7,\n",
    "\n",
    "        # Control and Privacy\n",
    "        'surveillance': -0.8, 'monitor': -0.6, 'control': -0.6, 'invasion': -0.7,\n",
    "        'privacy': -0.7, 'intrusive': -0.7, 'oversight': -0.5\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'positive_terms': positive_terms,\n",
    "        'negative_terms': negative_terms\n",
    "    }\n",
    "\n",
    "def create_industry_dictionaries():\n",
    "    \"\"\"Create comprehensive industry dictionaries using domain knowledge\"\"\"\n",
    "    print(\"Creating industry dictionaries...\")\n",
    "    \n",
    "    industry_terms = {\n",
    "        'healthcare': [\n",
    "            'doctor', 'physician', 'nurse', 'hospital', 'clinic', 'patient', 'care',\n",
    "            'medical', 'healthcare', 'health care', 'medicine', 'pharma', 'clinical'\n",
    "        ],\n",
    "\n",
    "        'finance': [\n",
    "            'bank', 'banking', 'investment', 'investor', 'loan', 'credit', \n",
    "            'financial', 'finance', 'trading', 'insurance', 'fintech'\n",
    "        ],\n",
    "\n",
    "        'manufacturing': [\n",
    "            'factory', 'manufacturing', 'production', 'assembly', 'supply chain',\n",
    "            'industrial', 'automotive', 'machinery', 'robotics', 'automation'\n",
    "        ],\n",
    "\n",
    "        'retail': [\n",
    "            'store', 'shop', 'retail', 'e-commerce', 'customer', 'consumer',\n",
    "            'inventory', 'merchandising', 'commerce', 'shopping'\n",
    "        ],\n",
    "\n",
    "        'education': [\n",
    "            'school', 'university', 'college', 'student', 'teacher', 'professor',\n",
    "            'education', 'learning', 'teaching', 'training', 'academic'\n",
    "        ],\n",
    "\n",
    "        'technology': [\n",
    "            'software', 'hardware', 'tech', 'technology', 'computer', 'digital',\n",
    "            'it', 'internet', 'web', 'app', 'computing', 'cloud'\n",
    "        ],\n",
    "\n",
    "        'media': [\n",
    "            'media', 'news', 'entertainment', 'publishing', 'content', \n",
    "            'social media', 'journalist', 'writing', 'advertising'\n",
    "        ],\n",
    "\n",
    "        'legal': [\n",
    "            'legal', 'lawyer', 'attorney', 'law firm', 'regulatory', 'compliance',\n",
    "            'court', 'litigation', 'judge', 'justice', 'contract'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Industry term weights to reflect their importance or specificity\n",
    "    industry_term_weights = {\n",
    "        'healthcare': {'hospital': 5, 'doctor': 4, 'patient': 3, 'medical': 2, 'healthcare': 5},\n",
    "        'finance': {'bank': 5, 'investment': 4, 'financial': 3, 'loan': 2, 'finance': 5},\n",
    "        'manufacturing': {'factory': 5, 'manufacturing': 5, 'production': 4, 'assembly': 3},\n",
    "        'retail': {'store': 4, 'retail': 5, 'e-commerce': 5, 'consumer': 3},\n",
    "        'education': {'school': 5, 'university': 5, 'student': 4, 'education': 5},\n",
    "        'technology': {'software': 4, 'tech': 5, 'technology': 5, 'digital': 3},\n",
    "        'media': {'media': 5, 'news': 4, 'content': 3, 'publishing': 4},\n",
    "        'legal': {'lawyer': 5, 'legal': 5, 'law': 4, 'attorney': 5}\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'industry_terms': industry_terms,\n",
    "        'industry_term_weights': industry_term_weights\n",
    "    }\n",
    "\n",
    "def create_job_dictionaries():\n",
    "    \"\"\"Create dictionaries related to job roles and occupations\"\"\"\n",
    "    print(\"Creating job dictionaries...\")\n",
    "    \n",
    "    job_terms = {\n",
    "        'management': [\n",
    "            'ceo', 'chief executive', 'cfo', 'cio', 'cto', 'coo', 'executive',\n",
    "            'manager', 'supervisor', 'director', 'leadership', 'administration'\n",
    "        ],\n",
    "\n",
    "        'engineering': [\n",
    "            'engineer', 'developer', 'programmer', 'coder', 'data scientist',\n",
    "            'machine learning engineer', 'ai engineer', 'software engineer',\n",
    "            'technical', 'architect', 'DevOps'\n",
    "        ],\n",
    "\n",
    "        'creative': [\n",
    "            'designer', 'writer', 'artist', 'content creator', 'creative',\n",
    "            'marketer', 'marketing', 'advertiser', 'author', 'editor'\n",
    "        ],\n",
    "\n",
    "        'education': [\n",
    "            'teacher', 'professor', 'instructor', 'educator', 'faculty',\n",
    "            'academic', 'trainer', 'teaching', 'tutor', 'lecturer'\n",
    "        ],\n",
    "\n",
    "        'healthcare': [\n",
    "            'doctor', 'nurse', 'physician', 'surgeon', 'medical professional',\n",
    "            'pharmacist', 'therapist', 'healthcare worker', 'clinician'\n",
    "        ],\n",
    "\n",
    "        'finance': [\n",
    "            'banker', 'accountant', 'financial analyst', 'trader', 'investor',\n",
    "            'broker', 'financial advisor', 'auditor', 'actuary'\n",
    "        ],\n",
    "\n",
    "        'service': [\n",
    "            'customer service', 'retail worker', 'sales associate', 'cashier',\n",
    "            'receptionist', 'assistant', 'representative', 'clerk'\n",
    "        ],\n",
    "\n",
    "        'manufacturing': [\n",
    "            'factory worker', 'machine operator', 'assembler', 'production worker',\n",
    "            'technician', 'mechanic', 'quality control', 'maintenance'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'job_terms': job_terms\n",
    "    }\n",
    "\n",
    "def create_technology_dictionaries():\n",
    "    \"\"\"Create dictionaries for AI and technology terms\"\"\"\n",
    "    print(\"Creating technology dictionaries...\")\n",
    "    \n",
    "    technology_terms = {\n",
    "        'machine_learning': [\n",
    "            'machine learning', 'ml', 'artificial intelligence', 'ai', 'algorithm',\n",
    "            'deep learning', 'neural network', 'data science'\n",
    "        ],\n",
    "\n",
    "        'nlp': [\n",
    "            'natural language processing', 'nlp', 'language model', 'llm',\n",
    "            'large language model', 'chatbot', 'gpt', 'bert'\n",
    "        ],\n",
    "\n",
    "        'computer_vision': [\n",
    "            'computer vision', 'image recognition', 'object detection',\n",
    "            'facial recognition', 'image processing'\n",
    "        ],\n",
    "\n",
    "        'robotics': [\n",
    "            'robot', 'robotics', 'automation', 'autonomous', 'self-driving',\n",
    "            'robotic process automation', 'rpa'\n",
    "        ],\n",
    "\n",
    "        'ai_infrastructure': [\n",
    "            'gpu', 'cloud computing', 'edge computing', 'federated learning',\n",
    "            'ai chip', 'compute', 'transformer'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # AI product models\n",
    "    ai_models = [\n",
    "        'gpt', 'chatgpt', 'gpt-4', 'gpt-3', 'dall-e', 'bard', 'palm',\n",
    "        'llama', 'claude', 'stable diffusion', 'midjourney', 'gemini'\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        'technology_terms': technology_terms,\n",
    "        'ai_models': ai_models\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Feature Extraction Functions\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def detect_industries(text, industry_terms, industry_term_weights=None):\n",
    "    \"\"\"Detect industries mentioned in text with weighted terms\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "        \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Count occurrences of each category's keywords with weights\n",
    "    category_scores = defaultdict(float)\n",
    "    \n",
    "    for category, terms in industry_terms.items():\n",
    "        for term in terms:\n",
    "            count = text_lower.count(term)\n",
    "            if count > 0:\n",
    "                # Apply term-specific weight if available\n",
    "                weight = 1.0\n",
    "                if industry_term_weights and category in industry_term_weights and term in industry_term_weights[category]:\n",
    "                    weight = industry_term_weights[category][term]\n",
    "                \n",
    "                # Apply additional weight for longer, more specific terms\n",
    "                length_weight = min(1.0, 0.5 + len(term) / 20.0)\n",
    "                \n",
    "                # Calculate final score\n",
    "                score = count * weight * length_weight\n",
    "                category_scores[category] += score\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the categories (without scores)\n",
    "    return [category for category, _ in sorted_categories]\n",
    "\n",
    "def detect_jobs(text, job_terms):\n",
    "    \"\"\"Detect job categories mentioned in text\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "        \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Count occurrences of each category's keywords\n",
    "    category_scores = defaultdict(float)\n",
    "    \n",
    "    for category, terms in job_terms.items():\n",
    "        for term in terms:\n",
    "            count = text_lower.count(term)\n",
    "            if count > 0:\n",
    "                # Apply additional weight for longer, more specific terms\n",
    "                length_weight = min(1.0, 0.5 + len(term) / 20.0)\n",
    "                \n",
    "                # Calculate final score\n",
    "                score = count * length_weight\n",
    "                category_scores[category] += score\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the categories (without scores)\n",
    "    return [category for category, _ in sorted_categories]\n",
    "\n",
    "def identify_technologies(text, technology_terms, ai_models):\n",
    "    \"\"\"Identify AI technologies mentioned in the text\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return {}\n",
    "        \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    found_techs = {}\n",
    "    \n",
    "    # Technology categories\n",
    "    for tech_category, keywords in technology_terms.items():\n",
    "        matched_keywords = [k for k in keywords if k in text_lower]\n",
    "        if matched_keywords:\n",
    "            # Sort by length (longer terms are typically more specific)\n",
    "            matched_keywords.sort(key=len, reverse=True)\n",
    "            found_techs[tech_category] = matched_keywords\n",
    "    \n",
    "    # AI models\n",
    "    found_models = [model for model in ai_models if model.lower() in text_lower]\n",
    "    if found_models:\n",
    "        found_techs['specific_models'] = found_models\n",
    "    \n",
    "    return found_techs\n",
    "\n",
    "def extract_organizations(text):\n",
    "    \"\"\"Extract organization names using simple heuristics\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # Known major AI companies and organizations\n",
    "    known_orgs = [\n",
    "        'OpenAI', 'Google', 'Microsoft', 'Apple', 'Amazon', 'Meta', 'Facebook',\n",
    "        'IBM', 'Anthropic', 'NVIDIA', 'Intel', 'AMD', 'Tesla', 'DeepMind'\n",
    "    ]\n",
    "    \n",
    "    # Find known organizations in the text\n",
    "    found_orgs = []\n",
    "    for org in known_orgs:\n",
    "        if org.lower() in text.lower():\n",
    "            found_orgs.append(org)\n",
    "    \n",
    "    # Limit to top 5\n",
    "    return found_orgs[:5]\n",
    "\n",
    "def analyze_sentiment(text, positive_terms, negative_terms, industry=None):\n",
    "    \"\"\"Analyze sentiment of the article regarding AI impact with domain-specific lexicon\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return {\n",
    "            'overall': 0,\n",
    "            'base': 0,\n",
    "            'lexicon': 0,\n",
    "            'proximity': 0,\n",
    "            'industry': 0\n",
    "        }\n",
    "    \n",
    "    # Base sentiment from TextBlob\n",
    "    base_sentiment = TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    # Custom domain-specific lexicon approach\n",
    "    text_lower = text.lower()\n",
    "    sentences = text.split('.')\n",
    "    \n",
    "    # 1. Calculate overall sentiment using domain-specific lexicon\n",
    "    positive_matches = 0\n",
    "    positive_score = 0\n",
    "    negative_matches = 0\n",
    "    negative_score = 0\n",
    "    \n",
    "    # Count and score positive terms\n",
    "    for term, value in positive_terms.items():\n",
    "        count = text_lower.count(term)\n",
    "        if count > 0:\n",
    "            positive_matches += count\n",
    "            positive_score += value * count\n",
    "    \n",
    "    # Count and score negative terms\n",
    "    for term, value in negative_terms.items():\n",
    "        count = text_lower.count(term)\n",
    "        if count > 0:\n",
    "            negative_matches += count\n",
    "            negative_score += value * count\n",
    "    \n",
    "    # 2. Calculate proximity between AI terms and impact terms\n",
    "    ai_terms = ['ai', 'artificial intelligence', 'machine learning']\n",
    "    impact_terms = ['job', 'work', 'employee', 'career', 'industry']\n",
    "    \n",
    "    proximity_score = 0\n",
    "    proximity_count = 0\n",
    "    \n",
    "    # Check sentences containing both AI and impact terms\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        has_ai = any(term in sentence for term in ai_terms)\n",
    "        has_impact = any(term in sentence for term in impact_terms)\n",
    "        \n",
    "        if has_ai and has_impact:\n",
    "            # Calculate sentiment for this sentence\n",
    "            sent_sentiment = TextBlob(sentence).sentiment.polarity\n",
    "            proximity_score += sent_sentiment\n",
    "            proximity_count += 1\n",
    "    \n",
    "    # 3. Industry-specific sentiment (simplified)\n",
    "    industry_sentiment = 0\n",
    "    \n",
    "    # 4. Calculate final weighted sentiment scores\n",
    "    lexicon_sentiment = 0\n",
    "    if (positive_matches + negative_matches) > 0:\n",
    "        lexicon_sentiment = (positive_score + negative_score) / (positive_matches + negative_matches)\n",
    "    \n",
    "    proximity_sentiment = 0\n",
    "    if proximity_count > 0:\n",
    "        proximity_sentiment = proximity_score / proximity_count\n",
    "    \n",
    "    # Final weighted score\n",
    "    weights = {\n",
    "        'base': 0.2,\n",
    "        'lexicon': 0.4,\n",
    "        'proximity': 0.3,\n",
    "        'industry': 0.1\n",
    "    }\n",
    "    \n",
    "    final_sentiment = (\n",
    "        weights['base'] * base_sentiment +\n",
    "        weights['lexicon'] * lexicon_sentiment +\n",
    "        weights['proximity'] * proximity_sentiment +\n",
    "        weights['industry'] * industry_sentiment\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'overall': final_sentiment,\n",
    "        'base': base_sentiment,\n",
    "        'lexicon': lexicon_sentiment,\n",
    "        'proximity': proximity_sentiment,\n",
    "        'industry': industry_sentiment\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Main Functions\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def create_dictionaries():\n",
    "    \"\"\"Create all the dictionaries needed for analysis\"\"\"\n",
    "    dictionaries = {}\n",
    "    \n",
    "    # 1. Sentiment Dictionaries\n",
    "    dictionaries['sentiment'] = create_sentiment_dictionaries()\n",
    "    \n",
    "    # 2. Industry Dictionaries\n",
    "    dictionaries['industry'] = create_industry_dictionaries()\n",
    "    \n",
    "    # 3. Job Dictionaries\n",
    "    dictionaries['job'] = create_job_dictionaries()\n",
    "    \n",
    "    # 4. Technology Dictionaries\n",
    "    dictionaries['technology'] = create_technology_dictionaries()\n",
    "    \n",
    "    return dictionaries\n",
    "\n",
    "def add_features_to_dataset(df, dictionaries):\n",
    "    \"\"\"Add all the missing features to the dataset\"\"\"\n",
    "    print(\"Adding features to dataset...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_enhanced = df.copy()\n",
    "    \n",
    "    # Unpack dictionaries\n",
    "    sentiment_dict = dictionaries['sentiment']\n",
    "    industry_dict = dictionaries['industry']\n",
    "    job_dict = dictionaries['job']\n",
    "    technology_dict = dictionaries['technology']\n",
    "    \n",
    "    # 1. Detect industries\n",
    "    print(\"Detecting industries and jobs...\")\n",
    "    df_enhanced['detected_industries'] = df_enhanced['cleaned_text'].apply(\n",
    "        lambda x: detect_industries(\n",
    "            x, \n",
    "            industry_dict['industry_terms'], \n",
    "            industry_dict['industry_term_weights']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 2. Detect jobs\n",
    "    df_enhanced['detected_jobs'] = df_enhanced['cleaned_text'].apply(\n",
    "        lambda x: detect_jobs(x, job_dict['job_terms'])\n",
    "    )\n",
    "    \n",
    "    # 3. Identify technologies\n",
    "    print(\"Identifying AI technologies...\")\n",
    "    df_enhanced['ai_technologies'] = df_enhanced['cleaned_text'].apply(\n",
    "        lambda x: identify_technologies(\n",
    "            x, \n",
    "            technology_dict['technology_terms'],\n",
    "            technology_dict['ai_models']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 4. Extract organizations\n",
    "    print(\"Extracting organizations...\")\n",
    "    df_enhanced['top_organizations'] = df_enhanced['cleaned_text'].apply(extract_organizations)\n",
    "    \n",
    "    # 5. Analyze sentiment\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    df_enhanced['sentiment_scores'] = df_enhanced.apply(\n",
    "        lambda x: analyze_sentiment(\n",
    "            x['cleaned_text'],\n",
    "            sentiment_dict['positive_terms'],\n",
    "            sentiment_dict['negative_terms'],\n",
    "            x['detected_industries'][0] if len(x['detected_industries']) > 0 else None\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Extract components of sentiment\n",
    "    df_enhanced['sentiment_overall'] = df_enhanced['sentiment_scores'].apply(lambda x: x['overall'])\n",
    "    df_enhanced['sentiment_base'] = df_enhanced['sentiment_scores'].apply(lambda x: x['base'])\n",
    "    df_enhanced['sentiment_lexicon'] = df_enhanced['sentiment_scores'].apply(lambda x: x['lexicon'])\n",
    "    df_enhanced['sentiment_proximity'] = df_enhanced['sentiment_scores'].apply(lambda x: x['proximity'])\n",
    "    df_enhanced['sentiment_industry'] = df_enhanced['sentiment_scores'].apply(lambda x: x['industry'])\n",
    "    \n",
    "    # 6. Add primary industry and job\n",
    "    df_enhanced['primary_industry'] = df_enhanced['detected_industries'].apply(\n",
    "        lambda x: x[0] if len(x) > 0 else None\n",
    "    )\n",
    "    \n",
    "    df_enhanced['primary_job'] = df_enhanced['detected_jobs'].apply(\n",
    "        lambda x: x[0] if len(x) > 0 else None\n",
    "    )\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "def run_enhancement_pipeline():\n",
    "    \"\"\"Main function to run the enhancement pipeline\"\"\"\n",
    "    print(\"Starting enhancement pipeline...\")\n",
    "    \n",
    "    # 1. Load topic data\n",
    "    df = load_from_cache('data_with_topics.pkl')\n",
    "    if df is None:\n",
    "        print(\"ERROR: Could not load data from data_with_topics.pkl\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded data with {len(df)} articles\")\n",
    "    \n",
    "    # 2. Create dictionaries\n",
    "    dictionaries = create_dictionaries()\n",
    "    \n",
    "    # 3. Add features to dataset\n",
    "    df_enhanced = add_features_to_dataset(df, dictionaries)\n",
    "    \n",
    "    # 4. Save enhanced dataset\n",
    "    save_to_cache(df_enhanced, 'enhanced_data_with_features.pkl')\n",
    "    \n",
    "    print(\"Enhancement pipeline complete!\")\n",
    "    print(\"Enhanced data saved to 'enhanced_data_with_features.pkl'\")\n",
    "    \n",
    "    return df_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhancement pipeline...\n",
      "Loaded data with 184391 articles\n",
      "Creating sentiment dictionaries...\n",
      "Creating industry dictionaries...\n",
      "Creating job dictionaries...\n",
      "Creating technology dictionaries...\n",
      "Adding features to dataset...\n",
      "Detecting industries and jobs...\n",
      "Identifying AI technologies...\n",
      "Extracting organizations...\n",
      "Analyzing sentiment...\n",
      "Saved enhanced_data_with_features.pkl to cache\n",
      "Enhancement pipeline complete!\n",
      "Enhanced data saved to 'enhanced_data_with_features.pkl'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_enhancement_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
